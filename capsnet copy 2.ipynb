{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <!-- SVM, Small VGG Network, ArcFace, FCapNetwork -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset = \n",
      "['Grupo_0', 'Grupo_1', '.DS_Store', 'Grupo_4', 'Grupo_3', 'Grupo_2', 'Grupo_5']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Lambda\n",
    "\n",
    "\n",
    "\n",
    "image_size = (160, 120, 3)\n",
    "input_shape = (160, 120, 3)\n",
    "num_classes = 2\n",
    "num_capsules = 32  \n",
    "dim_capsules = 16  \n",
    "routing_iterations = 3  \n",
    "kernel_size = 5  \n",
    "learning_rate = 1e-5  \n",
    "dataset_path = \"data\"\n",
    "\n",
    "\n",
    "print('Our dataset = ')\n",
    "print(os.listdir(dataset_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Loading DataSet, LG Folder - 29 Subjects, with one corrupt sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, max_depth=5):\n",
    "    images = []\n",
    "    labels = []\n",
    "    names = []\n",
    "    corruptedFiles = []\n",
    "    image_extensions = [\"bmp\"]\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        current_depth = root[len(folder_path):].count(os.sep)\n",
    "\n",
    "        if ('IriTech' in root) or ('Iritech' in root) or ('iriTech' in root) or ('iritech' in root):\n",
    "            continue\n",
    "\n",
    "        if current_depth <= max_depth:\n",
    "            for file in files:\n",
    "                if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img = cv2.resize(img, (160, 120))\n",
    "                            images.append(img)\n",
    "                            # Binary label, '0' means Fit for Duty, others alcoholic\n",
    "                            labels.append(file[6] != '0')\n",
    "                            names.append(file)\n",
    "                    except:\n",
    "                        corruptedFiles.append(img_path)\n",
    "        else:\n",
    "            del dirs[:]\n",
    "\n",
    "    print(f\"Following {len(corruptedFiles)} files are corrupt or encountered error: \\n {corruptedFiles}\")\n",
    "    return np.array(images), np.array(labels), np.array(names)\n",
    "\n",
    "images, labels, names = load_images_from_folder(dataset_path)\n",
    "print(f\"Read {len(images)} images from the data folder with shape {images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri = random.randint(0, len(images) - 1)\n",
    "print(\"Randome index: \" + str(ri))\n",
    "plt.imshow(images[ri])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Split images and labels into 80-20 random train test split and train cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 70% train and 30% test\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the image data\n",
    "images_train = images_train / 255.0\n",
    "images_test = images_test / 255.0\n",
    "\n",
    "\n",
    "labels_train_cnn = to_categorical(labels_train, num_classes=2)\n",
    "labels_test_cnn = to_categorical(labels_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "import numpy as np\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    def __init__(self, num_capsules, dim_capsules, routing_iterations=3, **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsules = num_capsules\n",
    "        self.dim_capsules = dim_capsules\n",
    "        self.routing_iterations = routing_iterations\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(shape=[self.num_capsules, input_shape[1], self.dim_capsules, input_shape[2]],\n",
    "                                 initializer='glorot_uniform',\n",
    "                                 trainable=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.expand_dims(inputs, 1)\n",
    "        inputs_hat = tf.scan(lambda ac, x: tf.linalg.matvec(self.W, x), elems=inputs)\n",
    "        logits = tf.zeros(shape=[tf.shape(inputs_hat)[0], self.num_capsules, inputs.shape[1]])\n",
    "        for i in range(self.routing_iterations):\n",
    "            routing_weights = tf.nn.softmax(logits, axis=1)\n",
    "            weighted_prediction = tf.reduce_sum(routing_weights * inputs_hat, axis=2)\n",
    "            outputs = self.squash(weighted_prediction)\n",
    "            if i < self.routing_iterations - 1:\n",
    "                logits += tf.reduce_sum(inputs_hat * outputs[:, :, None, :], axis=-1)\n",
    "        return outputs\n",
    "\n",
    "    def squash(self, s):\n",
    "        s_squared_norm = tf.reduce_sum(tf.square(s), axis=-1, keepdims=True)\n",
    "        scale = s_squared_norm / (1 + s_squared_norm) / tf.sqrt(s_squared_norm + 1e-9)\n",
    "        return scale * s\n",
    "\n",
    "# Reconstruction network\n",
    "def build_decoder(caps_output, image_size=(120, 160)):\n",
    "    decoded = layers.Dense(512, activation='relu')(caps_output)\n",
    "    decoded = layers.Dense(1024, activation='relu')(decoded)\n",
    "    decoded = layers.Dense(np.prod(image_size), activation='sigmoid')(decoded)\n",
    "    decoded = layers.Reshape(target_shape=image_size)(decoded)\n",
    "    return decoded\n",
    "\n",
    "# Capsule Network model\n",
    "def build_capsule_network(input_shape, num_classes, num_capsules, dim_capsules, routing_iterations, kernel_size, learning_rate):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    conv1 = layers.Conv2D(64, kernel_size, activation='relu')(inputs)\n",
    "    conv2 = layers.Conv2D(128, kernel_size, activation='relu')(conv1)\n",
    "\n",
    "    primary_caps = layers.Conv2D(256, kernel_size, strides=2, padding='valid')(conv2)\n",
    "    primary_caps = layers.Reshape((-1, dim_capsules))(primary_caps)\n",
    "    \n",
    "    capsules = CapsuleLayer(num_capsules=num_capsules, dim_capsules=dim_capsules, routing_iterations=routing_iterations)(primary_caps)\n",
    "    \n",
    "    capsules_output = layers.Lambda(lambda z: tf.norm(z, axis=-1))(capsules)\n",
    "    output = layers.Dense(num_classes, activation='sigmoid')(capsules_output)\n",
    "    \n",
    "    decoder_output = build_decoder(capsules_output)\n",
    "    \n",
    "    model = models.Model(inputs=inputs, outputs=[output, decoder_output])\n",
    "    \n",
    "    loss = [losses.BinaryCrossentropy(), 'mse']\n",
    "    loss_weights = [1.0, 0.0005]\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=loss, loss_weights=loss_weights,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquashLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SquashLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        s = inputs\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=-1, keepdims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + 1e-7)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        return squash_factor * s / safe_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class WTilingLayer(Layer):\n",
    "    def __init__(self, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims, init_sigma=0.1, **kwargs):\n",
    "        super(WTilingLayer, self).__init__(**kwargs)\n",
    "        self.caps1_n_caps = caps1_n_caps\n",
    "        self.caps2_n_caps = caps2_n_caps\n",
    "        self.caps2_n_dims = caps2_n_dims\n",
    "        self.caps1_n_dims = caps1_n_dims\n",
    "        self.init_sigma = init_sigma\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        W_init = tf.random.normal(\n",
    "            shape=(1, self.caps1_n_caps, self.caps2_n_caps, self.caps2_n_dims, self.caps1_n_dims),\n",
    "            stddev=self.init_sigma, dtype=tf.float32, name=\"W_init\"\n",
    "        )\n",
    "        self.W = tf.Variable(W_init, name=\"W\", trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        caps1_output = inputs[0]\n",
    "        X = inputs\n",
    "        batch_size = tf.shape(X)[0]\n",
    "        W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "        return W_tiled\n",
    "\n",
    "# Example usage:\n",
    "# layer = CustomCapsuleLayer(caps1_n_caps=32, caps2_n_caps=10, caps2_n_dims=16, caps1_n_dims=8)\n",
    "# W_tiled, caps1_output_tiled = layer([caps1_output, X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TilingLayer(Layer):\n",
    "    def __init__(self, caps2_n_caps, **kwargs):\n",
    "        super(TilingLayer, self).__init__(**kwargs)\n",
    "        self.caps2_n_caps = caps2_n_caps\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.reshape(inputs, [-1, 119808, 8])\n",
    "        caps1_output_expanded = tf.expand_dims(inputs, -1, name=\"caps1_output_expanded\")\n",
    "        caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2, name=\"caps1_output_tile\")\n",
    "        caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, self.caps2_n_caps, 1, 1], name=\"caps1_output_tiled\")\n",
    "        return caps1_output_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMulitplier(Layer):\n",
    "    def __init__(self, w_tiled, **kwargs):\n",
    "        super(MatMulitplier, self).__init__(**kwargs)\n",
    "        self.w_tiled = w_tiled\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        print(inputs[0].shape)\n",
    "        print(inputs[1].shape)\n",
    "        caps2_predicted = tf.matmul(inputs[0], inputs[1])\n",
    "        return caps2_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (160, 120, 1)\n",
    "inputs = layers.Input(shape=input_shape)  \n",
    "\n",
    "conv1 = layers.Conv2D(256, 9, strides=1, activation='relu', name=\"conv1\")(inputs)\n",
    "conv2 = layers.Conv2D(256, 9, strides=2, activation='relu', name=\"conv2\")(conv1)\n",
    "\n",
    "caps1_raw = layers.Reshape((-1, 32, 8), name=\"caps1_raw\")(conv2)\n",
    "squashed_output = SquashLayer(name=\"caps1_output\")(caps1_raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 10, 16), dtype=float32, sparse=False, name=keras_tensor_10>',)\n  • kwargs={'mask': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K\u001b[38;5;241m.\u001b[39msqrt(K\u001b[38;5;241m.\u001b[39msum(K\u001b[38;5;241m.\u001b[39msquare(inputs), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m K\u001b[38;5;241m.\u001b[39mepsilon())\n\u001b[1;32m     35\u001b[0m digit_caps \u001b[38;5;241m=\u001b[39m DigitCapsuleLayer()(squashed_output)\n\u001b[0;32m---> 36\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_layer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdigit_caps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/lambda_layer.py:95\u001b[0m, in \u001b[0;36mLambda.compute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mshape, output_spec)\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe could not automatically infer the shape of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe Lambda\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms output. Please specify the `output_shape` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument for this Lambda layer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m         )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape):\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_shape(input_shape)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 10, 16), dtype=float32, sparse=False, name=keras_tensor_10>',)\n  • kwargs={'mask': 'None'}"
     ]
    }
   ],
   "source": [
    "class DigitCapsuleLayer(layers.Layer):\n",
    "    # creating a layer class in keras\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DigitCapsuleLayer, self).__init__(**kwargs)\n",
    "        self.kernel_initializer = initializers.get('glorot_uniform')\n",
    "    \n",
    "    def build(self, input_shape): \n",
    "        # initialize weight matrix for each capsule in lower layer\n",
    "        self.W = self.add_weight(shape = [2, 32*72*52, 16, 8], initializer = self.kernel_initializer, name = 'weights')\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        inputs = K.expand_dims(inputs, 1)\n",
    "        inputs = K.tile(inputs, [1, 2, 1, 1])\n",
    "        # matrix multiplication b/w previous layer output and weight matrix\n",
    "        inputs = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs)\n",
    "        b = tf.zeros(shape = [K.shape(inputs)[0], 10, 32*72*52])\n",
    "        \n",
    "# routing algorithm with updating coupling coefficient c, using scalar product b/w input capsule and output capsule\n",
    "        for i in range(3-1):\n",
    "            c = tf.nn.softmax(b, dim=1)\n",
    "            s = K.batch_dot(c, inputs, [2, 2])\n",
    "            v = squash(s)\n",
    "            b = b + K.batch_dot(v, inputs, [2,3])\n",
    "            \n",
    "        return v \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, 10, 16])\n",
    "    \n",
    "    \n",
    "    \n",
    "def output_layer(inputs):\n",
    "    return K.sqrt(K.sum(K.square(inputs), -1) + K.epsilon())\n",
    " \n",
    "digit_caps = DigitCapsuleLayer()(squashed_output)\n",
    "outputs = Lambda(output_layer)(digit_caps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_n_caps = 2\n",
    "caps2_n_dims = 16\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "W_tiled = WTilingLayer(32*72*52, caps2_n_caps, caps2_n_dims, 8, init_sigma, name=\"w_tiled\")(caps1_output)\n",
    "caps1_output_tiled = TilingLayer(caps2_n_caps)(caps1_output)\n",
    "inputs = [W_tiled, caps1_output_tiled]\n",
    "caps2_predicted = MatMulitplier(w_tiled=W_tiled, name=\"caps2_predicted\")(inputs)\n",
    "# output = layers.Dense(num_classes, activation='sigmoid')(caps2_predicted)\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=[caps2_predicted])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_capsule_network(input_shape, num_classes, num_capsules, dim_capsules, routing_iterations, kernel_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train images count: {len(images_train)}\")\n",
    "print(f\"Image Shape {images_train[0].shape}\")\n",
    "print(f\"Test images count: {len(images_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.fit(\n",
    "    images_train,\n",
    "    labels_train_cnn,\n",
    "    epochs=10,\n",
    "    validation_data=(images_test, labels_test_cnn)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing model\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(images_test, labels_test_cnn)\n",
    "print(f\"CNN Test Accuracy: {cnn_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn_model.predict(images_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(labels_test_cnn, axis=1)\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=['Fit for Duty', 'Alcoholic'])\n",
    "print(report)\n",
    "\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f'Overall Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTest = 0\n",
    "correctTest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testImagePath = 'images/test2.png'\n",
    "# testImg = cv2.imread(testImagePath, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "r_in = random.randint(0, len(images) - 1)\n",
    "\n",
    "testImg = images[r_in]\n",
    "testLabel = labels[r_in]\n",
    "# testImg = cv2.resize(testImg, image_size)\n",
    "\n",
    "plt.imshow(testImg, cmap='gray')\n",
    "\n",
    "testImg = np.expand_dims(testImg, axis=0)\n",
    "\n",
    "print(testImg.shape)\n",
    "\n",
    "prediction = cnn_model.predict(testImg)\n",
    "prediction = np.argmax(prediction[0])\n",
    "\n",
    "totalTest +=1\n",
    "correctTest += prediction==testLabel\n",
    "\n",
    "prediction = 'Alcoholic' if prediction else 'Fit for duty'\n",
    "testLabel = 'Alcoholic' if testLabel else 'Fit for duty'\n",
    "plt.title(f'Name: {names[r_in]}\\n\\nPrediction: {prediction}\\nActual: {testLabel}\\n\\nAccuracy: {correctTest/totalTest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(\"./Models/ResNet50Classification/NonAugmented.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

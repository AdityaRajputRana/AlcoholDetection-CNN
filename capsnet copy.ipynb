{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <!-- SVM, Small VGG Network, ArcFace, FCapNetwork -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset = \n",
      "['Grupo_0', 'Grupo_1', '.DS_Store', 'Grupo_4', 'Grupo_3', 'Grupo_2', 'Grupo_5']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "image_size = (160, 120, 3)\n",
    "input_shape = (160, 120, 3)\n",
    "num_classes = 2\n",
    "num_capsules = 32  \n",
    "dim_capsules = 16  \n",
    "routing_iterations = 3  \n",
    "kernel_size = 5  \n",
    "learning_rate = 1e-5  \n",
    "dataset_path = \"data\"\n",
    "\n",
    "\n",
    "print('Our dataset = ')\n",
    "print(os.listdir(dataset_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Loading DataSet, LG Folder - 29 Subjects, with one corrupt sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, max_depth=5):\n",
    "    images = []\n",
    "    labels = []\n",
    "    names = []\n",
    "    corruptedFiles = []\n",
    "    image_extensions = [\"bmp\"]\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        current_depth = root[len(folder_path):].count(os.sep)\n",
    "\n",
    "        if ('IriTech' in root) or ('Iritech' in root) or ('iriTech' in root) or ('iritech' in root):\n",
    "            continue\n",
    "\n",
    "        if current_depth <= max_depth:\n",
    "            for file in files:\n",
    "                if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            img = cv2.resize(img, (160, 120))\n",
    "                            images.append(img)\n",
    "                            # Binary label, '0' means Fit for Duty, others alcoholic\n",
    "                            labels.append(file[6] != '0')\n",
    "                            names.append(file)\n",
    "                    except:\n",
    "                        corruptedFiles.append(img_path)\n",
    "        else:\n",
    "            del dirs[:]\n",
    "\n",
    "    print(f\"Following {len(corruptedFiles)} files are corrupt or encountered error: \\n {corruptedFiles}\")\n",
    "    return np.array(images), np.array(labels), np.array(names)\n",
    "\n",
    "images, labels, names = load_images_from_folder(dataset_path)\n",
    "print(f\"Read {len(images)} images from the data folder with shape {images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri = random.randint(0, len(images) - 1)\n",
    "print(\"Randome index: \" + str(ri))\n",
    "plt.imshow(images[ri])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Split images and labels into 80-20 random train test split and train cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into 70% train and 30% test\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalize the image data\n",
    "images_train = images_train / 255.0\n",
    "images_test = images_test / 255.0\n",
    "\n",
    "\n",
    "labels_train_cnn = to_categorical(labels_train, num_classes=2)\n",
    "labels_test_cnn = to_categorical(labels_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquashLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SquashLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        s = inputs\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=-1, keepdims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + 1e-7)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        return squash_factor * s / safe_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class WTilingLayer(Layer):\n",
    "    def __init__(self, caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims, init_sigma=0.1, **kwargs):\n",
    "        super(WTilingLayer, self).__init__(**kwargs)\n",
    "        self.caps1_n_caps = caps1_n_caps\n",
    "        self.caps2_n_caps = caps2_n_caps\n",
    "        self.caps2_n_dims = caps2_n_dims\n",
    "        self.caps1_n_dims = caps1_n_dims\n",
    "        self.init_sigma = init_sigma\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        W_init = tf.random.normal(\n",
    "            shape=(1, self.caps1_n_caps, self.caps2_n_caps, self.caps2_n_dims, self.caps1_n_dims),\n",
    "            stddev=self.init_sigma, dtype=tf.float32, name=\"W_init\"\n",
    "        )\n",
    "        self.W = tf.Variable(W_init, name=\"W\", trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        caps1_output = inputs[0]\n",
    "        X = inputs\n",
    "        batch_size = tf.shape(X)[0]\n",
    "        W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "        return W_tiled\n",
    "\n",
    "# Example usage:\n",
    "# layer = CustomCapsuleLayer(caps1_n_caps=32, caps2_n_caps=10, caps2_n_dims=16, caps1_n_dims=8)\n",
    "# W_tiled, caps1_output_tiled = layer([caps1_output, X])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TilingLayer(Layer):\n",
    "    def __init__(self, caps2_n_caps, **kwargs):\n",
    "        super(TilingLayer, self).__init__(**kwargs)\n",
    "        self.caps2_n_caps = caps2_n_caps\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.reshape(inputs, [-1, 119808, 8])\n",
    "        caps1_output_expanded = tf.expand_dims(inputs, -1, name=\"caps1_output_expanded\")\n",
    "        caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2, name=\"caps1_output_tile\")\n",
    "        caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, self.caps2_n_caps, 1, 1], name=\"caps1_output_tiled\")\n",
    "        return caps1_output_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatMulitplier(Layer):\n",
    "    def __init__(self, w_tiled, **kwargs):\n",
    "        super(MatMulitplier, self).__init__(**kwargs)\n",
    "        self.w_tiled = w_tiled\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        print(inputs[0].shape)\n",
    "        print(inputs[1].shape)\n",
    "        caps2_predicted = tf.matmul(inputs[0], inputs[1])\n",
    "        return caps2_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 119808, 2, 16, 8)\n",
      "(None, 119808, 2, 8, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_503CL… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119808</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ keras_tensor_504CL… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119808</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ caps2_predicted     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119808</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ keras_tensor_503… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MatMulitplier</span>)     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)            │            │ keras_tensor_504… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ keras_tensor_503CL… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m119808\u001b[0m, \u001b[38;5;34m2\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m8\u001b[0m)            │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ keras_tensor_504CL… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m119808\u001b[0m, \u001b[38;5;34m2\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ caps2_predicted     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m119808\u001b[0m, \u001b[38;5;34m2\u001b[0m, │          \u001b[38;5;34m0\u001b[0m │ keras_tensor_503… │\n",
       "│ (\u001b[38;5;33mMatMulitplier\u001b[0m)     │ \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m)            │            │ keras_tensor_504… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_shape = (160, 120, 1)\n",
    "inputs = layers.Input(shape=input_shape)  \n",
    "\n",
    "conv1 = layers.Conv2D(256, 9, strides=1, activation='relu', name=\"conv1\")(inputs)\n",
    "conv2 = layers.Conv2D(256, 9, strides=2, activation='relu', name=\"conv2\")(conv1)\n",
    "\n",
    "caps1_raw = layers.Reshape((-1, 32, 8), name=\"caps1_raw\")(conv2)\n",
    "caps1_output = SquashLayer(name=\"caps1_output\")(caps1_raw)\n",
    "\n",
    "caps2_n_caps = 2\n",
    "caps2_n_dims = 16\n",
    "\n",
    "init_sigma = 0.1\n",
    "\n",
    "W_tiled = WTilingLayer(32*72*52, caps2_n_caps, caps2_n_dims, 8, init_sigma, name=\"w_tiled\")(caps1_output)\n",
    "caps1_output_tiled = TilingLayer(caps2_n_caps)(caps1_output)\n",
    "inputs = [W_tiled, caps1_output_tiled]\n",
    "caps2_predicted = MatMulitplier(w_tiled=W_tiled, name=\"caps2_predicted\")(inputs)\n",
    "\n",
    "\n",
    "#Complete the CapsNet here\n",
    "\n",
    "model = models.Model(inputs=inputs, outputs=[caps2_predicted])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_capsule_network(input_shape, num_classes, num_capsules, dim_capsules, routing_iterations, kernel_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train images count: {len(images_train)}\")\n",
    "print(f\"Image Shape {images_train[0].shape}\")\n",
    "print(f\"Test images count: {len(images_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.fit(\n",
    "    images_train,\n",
    "    labels_train_cnn,\n",
    "    epochs=10,\n",
    "    validation_data=(images_test, labels_test_cnn)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing model\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(images_test, labels_test_cnn)\n",
    "print(f\"CNN Test Accuracy: {cnn_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = cnn_model.predict(images_test)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(labels_test_cnn, axis=1)\n",
    "\n",
    "report = classification_report(true_classes, predicted_classes, target_names=['Fit for Duty', 'Alcoholic'])\n",
    "print(report)\n",
    "\n",
    "accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "print(f'Overall Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalTest = 0\n",
    "correctTest = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testImagePath = 'images/test2.png'\n",
    "# testImg = cv2.imread(testImagePath, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "r_in = random.randint(0, len(images) - 1)\n",
    "\n",
    "testImg = images[r_in]\n",
    "testLabel = labels[r_in]\n",
    "# testImg = cv2.resize(testImg, image_size)\n",
    "\n",
    "plt.imshow(testImg, cmap='gray')\n",
    "\n",
    "testImg = np.expand_dims(testImg, axis=0)\n",
    "\n",
    "print(testImg.shape)\n",
    "\n",
    "prediction = cnn_model.predict(testImg)\n",
    "prediction = np.argmax(prediction[0])\n",
    "\n",
    "totalTest +=1\n",
    "correctTest += prediction==testLabel\n",
    "\n",
    "prediction = 'Alcoholic' if prediction else 'Fit for duty'\n",
    "testLabel = 'Alcoholic' if testLabel else 'Fit for duty'\n",
    "plt.title(f'Name: {names[r_in]}\\n\\nPrediction: {prediction}\\nActual: {testLabel}\\n\\nAccuracy: {correctTest/totalTest}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(\"./Models/ResNet50Classification/NonAugmented.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following 0 files are corrupt or encountered error: \n",
      " []\n",
      "Read 2820 images from the data folder with shape (2820, 160, 120)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Dataset parameters\n",
    "dataset_path = \"data\"\n",
    "image_size = (120, 160)  # As per the paper\n",
    "image_extensions = [\"bmp\"]  # Update this if other extensions exist\n",
    "\n",
    "# Function to load images from the LG folder (following the exact structure)\n",
    "def load_images_from_folder(folder_path, max_depth = 5):\n",
    "    images = []\n",
    "    labels = []\n",
    "    names = []\n",
    "    corruptedFiles = []\n",
    "    image_extensions = [\"bmp\"]\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        current_depth = root[len(folder_path):].count(os.sep)\n",
    "\n",
    "        if ('IriTech' in root) or ('Iritech' in root) or ('iriTech' in root) or ('iritech' in root):\n",
    "            continue\n",
    "        \n",
    "\n",
    "        if current_depth <= max_depth:\n",
    "            for file in files:\n",
    "                if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                    img_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                        if img is not None:\n",
    "                            img = cv2.resize(img, image_size)\n",
    "                            images.append(img)\n",
    "                            labels.append(file[6]!='0')\n",
    "                            names.append(file)\n",
    "                    except:\n",
    "                        corruptedFiles.append(img_path)\n",
    "\n",
    "        else:\n",
    "            del dirs[:]\n",
    "    \n",
    "    print(f\"Following {len(corruptedFiles)} files are corrupt or encountered error: \\n {corruptedFiles}\")\n",
    "\n",
    "    return np.array(images), np.array(labels), np.array(names)\n",
    "\n",
    "images, labels, names = load_images_from_folder(dataset_path)\n",
    "print(f\"Read {len(images)} images from the data folder with shape {images.shape}\")\n",
    "# Flatten images to vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(index):\n",
    "    plt.imshow(images[index], cmap='gray')\n",
    "    plt.title('Alcoholic' if labels[index] else 'Fit for Duty')\n",
    "    print(images[index].shape)\n",
    "\n",
    "showImg(900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Bias towards Alcohol Detection\n",
    "\n",
    "#Splitting Classes\n",
    "alcoholicClass = [images[i] for i in range(len(labels)) if labels[i] == 1]\n",
    "nonAlcoholicClass = [images[i] for i in range(len(labels)) if labels[i] == 0]\n",
    "\n",
    "alcoholicClass = np.array(alcoholicClass)\n",
    "nonAlcoholicClass = np.array(nonAlcoholicClass)\n",
    "\n",
    "#Data Generator Setup\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=4,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.025,\n",
    "    zoom_range=0.25,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "#Augmentation:\n",
    "\n",
    "n1 = len(nonAlcoholicClass)\n",
    "n2 = len(alcoholicClass)\n",
    "target_size = n2\n",
    "augmentation_needed = target_size - n1\n",
    "\n",
    "print(f'Number of samples in Class 1 (FFD): {n1}')\n",
    "print(f'Number of samples in Class 2 (Alcoholic): {n2}')\n",
    "print(f'Augmenting {augmentation_needed} images for Class 1 to match Class 2.')\n",
    "\n",
    "augmented_images = []\n",
    "for i in range(augmentation_needed):\n",
    "    img = nonAlcoholicClass[i % n1]  \n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    img = np.expand_dims(img, axis=0)  \n",
    "    augmented_img = next(datagen.flow(img, batch_size=1))[0]\n",
    "    augmented_img = np.squeeze(augmented_img, axis=-1)\n",
    "    augmented_img = augmented_img.astype(int)\n",
    "    augmented_images.append(augmented_img)\n",
    "\n",
    "augmented_images = np.array(augmented_images)\n",
    "\n",
    "concagtedClassNon = np.concatenate([nonAlcoholicClass, augmented_images], axis=0)\n",
    "concagtedClassNon = np.concatenate([nonAlcoholicClass, augmented_images], axis=0)\n",
    "\n",
    "print(f'New size of Class 1: {len(alcoholicClass)}')\n",
    "print(f'New size of Class 2: {len(concagtedClassNon)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(images.shape[0], -1)  # Shape (N, 19200)\n",
    "\n",
    "# Split dataset into train (60%) and test (40%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.4, random_state=42)\n",
    "\n",
    "# Perform 5-fold cross-validation to tune hyperparameters\n",
    "svm = SVC(kernel='rbf')\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1],\n",
    "}\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best parameters from CV:\", grid_search.best_params_)\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model on the full training set\n",
    "best_svm.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_svm.predict(X_test)\n",
    "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
